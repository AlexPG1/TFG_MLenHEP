{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf90354-d8d2-4766-811a-c126822593b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# **Rèplica primera sessió - càrrega de dades**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaeeb08-1b65-4f76-8430-5c9c3f15fc65",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Experimentació càrrega de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11321b-ff73-4c4b-b14c-e77447fabca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atajos útils:\n",
    "# Ctrl + / --> comentar (en el numeric pad!)\n",
    "# Ctrl + ç --> comentar tb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7947b1-5c66-49f7-bfa0-4c5bdea5db17",
   "metadata": {},
   "source": [
    "Primerament instal·lem un parell de ferramentes útils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a51d4-052c-4e0c-9558-45da072d7442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt\n",
    "pip install lckr-jupyterlab-variableinspector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a31874-60b5-48d5-bef2-2ceb164e1303",
   "metadata": {},
   "source": [
    "Repliquem el mecanisme de càlcul de temps d'execució"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9a0346-e518-46c1-a3d1-41a182e3e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examen d'eficiència\n",
    "startTime = time.time()\n",
    "alltr = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quart'\\TFG\\RstudioPython\\Dades\\Normal\\all_train.csv\")\n",
    "endTime = time.time()\n",
    "print(endTime-startTime)\n",
    "\n",
    "# Tarda 63 segons! La meitat que el segon mecanisme en R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e02d4d6-6f49-42fc-a0bf-f50a7dc81c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# f1000a = open(r\"D:/OneDrive/Universitat/5. Quart'/TFG/RstudioPython/Dades/NoNormalTrue/xttbar_m1000_aug17.txt\", mode ='r')\n",
    "# f1000b = open(r\"D:/OneDrive/Universitat/5. Quart'/TFG/RstudioPython/Dades/NoNormalTrue/xttbar_m1000_aug4.txt\", mode ='r')\n",
    "# readme = open(r\"D:/OneDrive/Universitat/5. Quart'/TFG/RstudioPython/Dades/NoNormalTrue/xttbar_m1000_aug4.txt\")\n",
    "# lineslist = readme.readlines()\n",
    "# cols, rows = (int(val) for val in lines_list[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8278f4e4-f6f3-4a91-8bfc-725847726ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seleccionem únicament les dades signal/background\n",
    "milTrSignal = alltr.loc[(alltr[\"mass\"] == 1000) & (alltr[\"# label\"] == 1)]\n",
    "milTrBackground = alltr.loc[(alltr[\"mass\"] == 1000) & (alltr[\"# label\"] == 0)]\n",
    "# adult_names = titanic.loc[titanic[\"Age\"] > 35, \"Name\"]\n",
    "\n",
    "# Error detectat: & té major prioritat que ==, així que cal emprar parèntesis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e59662-f1f7-411d-ba71-27af0adbf9f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del(allTrBackground, allTrSignal) # Mètode per eliminar variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db1549-6d3e-4f02-bc0b-9218251d5390",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Càrrega de dades final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee738d1e-9cf5-402b-812c-83a523638ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cel·la definitiva - càrrega de dades\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "alltr = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quart'\\TFG\\RstudioPython\\Dades\\Normal\\all_train.csv\")\n",
    "miltr = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quart'\\TFG\\RstudioPython\\Dades\\Normal\\1000_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9891d24b-b273-4650-9196-3e9253353781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Trunquem les dades, seleccionem únicament 10 000. A més, la separem en la informació coneguda i la que pretenem predir.\n",
    "Xdata = np.array(miltr.loc[:,[\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\"]])\n",
    "# Ydata = np.array(miltr.loc[:,\"# label\"])\n",
    "Ydata = np.array(miltr.index)[1:10001]\n",
    "Xdata = Xdata[0:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d5dfe2-5743-4bc4-982a-10657320833f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(Xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba32ff-b584-4db1-81c0-ad0cc06170ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(miltr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe06bf-7984-4fcc-858e-0c3805f21ef3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# **Segona sessió: normalització, matrius de correlació i decision trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae57014-dc51-4da0-9341-faea5d40724d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Càrrega de dades (tr i tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b1f546-a955-4923-bcec-6ec9fbf4ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "\n",
    "miltr = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quint\\TFG\\RstudioPython\\Dades\\Normal\\1000_train.csv\")\n",
    "miltst = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quint\\TFG\\RstudioPython\\Dades\\Normal\\1000_test.csv\")\n",
    "alltr = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quint\\TFG\\RstudioPython\\Dades\\Normal\\all_train.csv\")\n",
    "alltst = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quint\\TFG\\RstudioPython\\Dades\\Normal\\all_test.csv\")\n",
    "\n",
    "# del(alltr,alltst)\n",
    "# del(miltr, miltst)\n",
    "\n",
    "# Per poder emetre un so quan acaba d'executar una cel·la\n",
    "from IPython.display import Audio\n",
    "sound_file = \"C:/Users/alexp/Downloads/beep.wav\"\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcacb35-3b76-4b18-b881-a342340d0d3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Matrius de correlació"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562e9b8-654a-4759-bbb3-78cdb50b58cd",
   "metadata": {},
   "source": [
    "Preprocesem les dades: seleccionem solament signal (`# label == 1`) i variables HL i pTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3618e0e1-b0dc-49c4-b283-0ddda0f5471a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "milTrSignal = miltr.loc[miltr.index == 1]\n",
    "milTrSignal = miltr.loc[:,[\"# label\",\"f6\",\"f10\",\"f14\",\"f18\",\"f21\",\"f22\",\"f23\",\"f24\",\"f25\"]]\n",
    "milTrSignal.columns = [\"Lept_pt\",\"j1_pt\",\"j2_pt\",\"j3_pt\",\"j4_pt\",\"m_jj\",\"m_jjj\",\"m_lv\",\"m_jlv\",\"m_wwbb\"]\n",
    "\n",
    "milTrBack = miltr.loc[miltr.index == 0]\n",
    "milTrBack = miltr.loc[:,[\"# label\",\"f6\",\"f10\",\"f14\",\"f18\",\"f21\",\"f22\",\"f23\",\"f24\",\"f25\"]]\n",
    "milTrBack.columns = [\"Lept_pt\",\"j1_pt\",\"j2_pt\",\"j3_pt\",\"j4_pt\",\"m_jj\",\"m_jjj\",\"m_lv\",\"m_jlv\",\"m_wwbb\"]\n",
    "\n",
    "allTrSignal = alltr.loc[alltr[\"# label\"] == 1]\n",
    "allTrSignal = alltr.iloc[:,[1,7,11,15,19,23,24,25,26,27,28]]\n",
    "allTrSignal.columns = [\"Lept_pt\",\"j1_pt\",\"j2_pt\",\"j3_pt\",\"j4_pt\",\"m_jj\",\"m_jjj\",\"m_lv\",\"m_jlv\",\"m_wwbb\",\"mass\"]\n",
    "\n",
    "Tr500Signal = allTrSignal.loc[allTrSignal[\"mass\"] <= 500]\n",
    "Tr750Signal = allTrSignal.loc[allTrSignal[\"mass\"] == 750]\n",
    "Tr1000Signal = allTrSignal.loc[allTrSignal[\"mass\"] == 1000]\n",
    "Tr1250Signal = allTrSignal.loc[allTrSignal[\"mass\"] == 1250]\n",
    "Tr1500Signal = allTrSignal.loc[allTrSignal[\"mass\"] == 1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa85cd-041a-44ad-a178-ac1a74c30f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(Tr500Signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feea95c6-ad4d-437b-8f12-9862ba8c5821",
   "metadata": {},
   "source": [
    "Representem la matriu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4beea-9569-414d-bfdd-4d8afd999df4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataframe = Tr750Signal\n",
    "dataframe = dataframe.iloc[:,0:10]\n",
    "\n",
    "# plt.matshow(milTrSignal.corr())\n",
    "# plt.show()\n",
    "f = plt.figure(figsize=(10, 10))\n",
    "plt.matshow(dataframe.corr(), fignum=f.number)\n",
    "\n",
    "plt.xticks(range(dataframe.select_dtypes(['number']).shape[1]), dataframe.select_dtypes(['number']).columns, fontsize=14, rotation=45)\n",
    "plt.yticks(range(dataframe.select_dtypes(['number']).shape[1]), dataframe.select_dtypes(['number']).columns, fontsize=14)\n",
    "\n",
    "# ax=plt.gca() #get the current axes\n",
    "# PCM=ax.get_children()[2]\n",
    "# cb = plt.colorbar(PCM,ax=ax)\n",
    "# cb.ax.tick_params(labelsize=14)\n",
    "\n",
    "plt.title('Correlation Matrix', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d9f035-322d-4cc1-9efe-d0e7680408dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corr = dataframe.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ede3c95-e1af-46ca-8c0a-95d300f43bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a4032-78d7-4ce5-aaed-c78f648c48f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7689ead2-451f-4f5d-80ed-25b5a4cea32e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Repliquem decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542d4e0-77f3-4699-8c41-45c3b0ccd8b4",
   "metadata": {},
   "source": [
    "Estudiem una mica algunes de les funcions que emprarem (`array` [bàsic de numpy], `bincount`, `arange`, `argwhere`, `flatten`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb00df5-ac35-4758-8864-b4bd2fd5ba13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bincount diguem-ne que fa un histograma de l'array\n",
    "y = np.array([1,2,3,1,2])\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc328092-3df3-47ee-bceb-22bd5b8d1ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# np.argwhere(condition) troba els elements que compleixen la condició\n",
    "# .flatten ho transforma en vector, en comptes de llista de llistes\n",
    "x = np.arange(5)\n",
    "np.argwhere(x<3).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582251d6-ad5b-4102-b583-05c859ea1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritme per a Decision Trees basat en https://www.youtube.com/watch?v=NxEHSAfFlK8&list=PLcWfeUsAys2k_xub3mHks85sBHZvg24Jd&index=5\n",
    "# Un parell d'ajusts, en la línia 94, afegisc un pas addicional per compatibilitzar bincounts amb les dades (float). No estic segur de si és adequat.\n",
    "\n",
    "\n",
    "# L'asterisc força a passar value explícitament quan es cree un node: Node(value = blabla)\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None,*,value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None # Si existeix un valor, aleshores hi ha al menys un fill, per tant no és --> false\n",
    "        \n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_features=None):\n",
    "        self.min_samples_split=min_samples_split\n",
    "        self.max_depth=max_depth\n",
    "        self.n_features=n_features\n",
    "        self.root=None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1], self.n_features)\n",
    "        self.root = self._grow_tree(X,y)\n",
    "        \n",
    "    def _grow_tree(self, X, y, depth = 0):\n",
    "        n_samples, n_feats = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "        \n",
    "        # Check the stopping criteria\n",
    "        if (depth>=self.max_depth or n_labels == 1 or n_samples < self.min_samples_split):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "        # Si tenim el màxim de profunditat, si tenim un node pur o arribem al mínim de mostres, no crearem més\n",
    "        \n",
    "        feat_idx = np.random.choice(n_feats, self.n_features, replace = False)\n",
    "        \n",
    "        # Find the best split\n",
    "        best_feature, best_thresh = self._best_split(X, y, feat_idx) # Lloc on incloem la part aleatòria dels DT\n",
    "        \n",
    "        # Create child nodes\n",
    "        left_idxs, right_idxs = self._split(X[:,best_feature], best_thresh)\n",
    "        left = self._grow_tree(X[left_idxs,:],y[left_idxs], depth+1)\n",
    "        right = self._grow_tree(X[right_idxs,:],y[right_idxs], depth+1)\n",
    "        return Node(best_feature, best_thresh, left, right)\n",
    "        \n",
    "        \n",
    "    def _best_split(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_idx, split_threshold = None, None\n",
    "        \n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "            \n",
    "            for thr in thresholds:\n",
    "                # Calculate Information gain\n",
    "                gain = self._information_gain(y, X_column, thr)\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_threshold = thr\n",
    "        \n",
    "        return split_idx, split_threshold\n",
    "    \n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        # Parent entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "        \n",
    "        # Create children\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        \n",
    "        if(len(left_idxs) == 0 or len(right_idxs) == 0):\n",
    "           return 0\n",
    "        \n",
    "        # Calculate weighted avg. entropy of children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y[left_idxs]),self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r    \n",
    "           \n",
    "        # Calculate IG\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "        \n",
    "    def _entropy(self, y):\n",
    "        uniq, inverse = np.unique(y, return_inverse=True) # Afegit per mi per poder fer el mateix amb floats en comptes d'int\n",
    "        hist = np.bincount(inverse)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p*np.log(p) for p in ps if p > 0])\n",
    "   \n",
    "    def _split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "        \n",
    "        \n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        value = counter.most_common(1)[0][0] # Mirar en Logistic Regression\n",
    "        return value\n",
    "                        \n",
    "\n",
    "    def predict(self,X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "    \n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "           return node.value\n",
    "           \n",
    "        if x[node.feature] <= node.threshold:\n",
    "           return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99f854-eb23-4a65-a261-2417eabfc286",
   "metadata": {},
   "source": [
    "Emprem aquest DT *artesanal* amb els datasets proposats al vídeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06e2a41-33f0-4e4a-a25c-6bea38f19345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# from DecisionTree import DecisionTree\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state = 1234\n",
    ")\n",
    "\n",
    "clf = DecisionTree()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "def accuracy(y_test, y_pred):\n",
    "    return np.sum(y_test == y_pred) / len(y_test)\n",
    "    \n",
    "acc = accuracy(y_test, predictions)\n",
    "print(acc)\n",
    "\n",
    "# Jugar amb més max_depth, diferents paràmetres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b950b1-6ea2-450e-aeca-8355b93743b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(Xdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663eefbd-f4e3-4cc0-932f-6a9d2fda3133",
   "metadata": {},
   "source": [
    "Intentem emprar aquest DT amb els nostres datasets. Seleccionem les columnes LL per a Xdata i els índexs per al Ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17af2f5-af4d-430a-835a-b5c94a111d1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prova 1: trunquem les dades, seleccionem únicamen 10 000\n",
    "Xdata = np.array(miltr.loc[:,[\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\"]])\n",
    "# Ydata = np.array(miltr.loc[:,\"# label\"])\n",
    "Ydata = np.array(miltr.index)[1:10001]\n",
    "Xdata = Xdata[0:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af4e00-ac73-4ac8-a9db-43d3110467d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prova 2: no fem split en test i train,  \n",
    "Xdata = np.array(miltr.loc[:,[\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\"]])\n",
    "# Ydata = np.array(miltr.loc[:,\"# label\"])\n",
    "Ydata = np.array(miltr.index)[0:50000]\n",
    "Xdata = Xdata[0:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858f2f7-943f-4b0a-aadd-beb2d0347558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "X, y = Xdata, Ydata\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=1, random_state = 1234\n",
    ")\n",
    "\n",
    "clf = DecisionTree(min_samples_split = 500, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "def accuracy(y_test, y_pred):\n",
    "    return np.sum(y_test == y_pred) / len(y_test)\n",
    "    \n",
    "acc = accuracy(y_test, predictions)\n",
    "print(acc)\n",
    "\n",
    "endTime = time.time()\n",
    "print(endTime-startTime)\n",
    "\n",
    "# Prova 1 amb 10.000 dades, None, None --> precisió de 1.0, temps d'execució ~ 15 minuts\n",
    "# Prova 2 amb 100.000 dades, min_samples_split = 500, max_depth=4 --> precisió de ; temps d'execució > 4 hores, descartat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602cb8ff-6b71-4201-82ae-07919f785f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca4259-0060-4da5-add8-eec62a1de7ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Ferramentes sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e14920-1440-4859-bb2b-6492fb08cd01",
   "metadata": {},
   "source": [
    "Una vegada hem replicat el codi bàsic d'un DT i hem interioritzat el procediment, emprem la llibreria sklearn, amb algoritmes més\n",
    "testats i optimitzats, entenc.\n",
    "El mètode anterior és ilustratiu, però inviable en termes de temps d'execució."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec447480-9cac-4da8-86d4-3403e07059ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prova 3: amb tots els esdeveniments\n",
    "Ydata = np.array(miltr.index)\n",
    "Xdata = np.array(miltr.loc[:,[\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4218918-1a8c-49a5-bc04-9ef037f92055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "startTime = time.time()\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 5)\n",
    "clf = clf.fit(Xdata, Ydata)\n",
    "\n",
    "# tree.plot_tree(clf)\n",
    "\n",
    "endTime = time.time()\n",
    "print(endTime-startTime) \n",
    "\n",
    "# Prova 2: 13 segons!?!?!\n",
    "# Prova 3 (tots els esdeveniments, max_depth = 5): 174 segons?\n",
    "\n",
    "\n",
    "# El plot del tree és un infern quan té massa depth, obviar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb2084-6956-432b-8253-72348596b6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f1408-597c-4db5-b55c-f54b2de9643c",
   "metadata": {
    "tags": []
   },
   "source": [
    "Carreguem ara també les dades test per avaluar el Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11f8ec-634d-4016-8bf0-7261f7e243a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "miltst = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quart'\\TFG\\RstudioPython\\Dades\\Normal\\1000_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0282130f-9060-453d-99bb-ede49d4e8482",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ytst = np.array(miltst.iloc[:,0])\n",
    "Xtst = np.array(miltst.loc[:,[\"# label\",\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a525d37-2bca-461e-8e66-5be73f94e222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(miltst)\n",
    "# print(Xtst)\n",
    "# print(Ytst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f93f70-2414-4ee7-a5f8-6789293c5658",
   "metadata": {},
   "source": [
    "`score` sembla que calcula la precisió mitjana (https://github.com/scikit-learn/scikit-learn/blob/093e0cf14/sklearn/base.py#L680) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf47708-efff-4aa3-b5cc-1d14a8cc4f43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc = clf.score(Xtst, Ytst)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c36961-a20a-42aa-a77e-38745d489f1a",
   "metadata": {},
   "source": [
    "Ara, unifiquem totes les parts de l'avaluació:\n",
    "\n",
    "0. Càrrega de dades\n",
    "1. Preparació de les dades i selecció de variables\n",
    "2. Càlcul del DT\n",
    "3. Avaluació del DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0884ec5e-e468-459a-82a3-ae7ff6f46a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ydata = np.array(alltr.iloc[:,[0]])\n",
    "\n",
    "print(Ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d10db-aa8a-4cae-bbae-17879b875a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(alltr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6003d43e-f2d9-4e5a-9655-a1c6fe003bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df63ff-0878-4981-b709-5f8984b5893e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part 1: definim Ydata, Ytst per a tots i Xdata, Xtst per a cada cas \n",
    "# Ydata = np.array(miltr.index)\n",
    "# Ytst = np.array(miltst.iloc[:,0])\n",
    "\n",
    "Ydata = np.array(alltr.iloc[:,[0]])\n",
    "Ytst = np.array(alltst.iloc[:,0])\n",
    "\n",
    "\n",
    "# a) LL \n",
    "# Xdata = np.array(miltr.loc[:,[\"# label\",\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\n",
    "#                               \"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\"]])\n",
    "# Xtst = np.array(miltst.loc[:,[\"# label\",\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\"\n",
    "#                               ,\"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\"]])\n",
    "\n",
    "# b) LL + HL \n",
    "# Xdata = np.array(miltr.loc[:,[\"# label\",\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\n",
    "#                               \"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\",\"f22\",\"f23\",\"f24\",\"f25\"]])\n",
    "# Xtst = np.array(miltst.loc[:,[\"# label\",\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\n",
    "#                               \"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\",\"f22\",\"f23\",\"f24\",\"f25\"]])\n",
    "\n",
    "# c) Selecció 1: f6 + HL\n",
    "# Xdata = np.array(miltr.iloc[:,[\"f6\",\"f21\",\"f22\",\"f23\",\"f24\",\"f25\"]])\n",
    "# Xtst = np.array(miltst.iloc[:,[\"f6\",\"f21\",\"f22\",\"f23\",\"f24\",\"f25\"]])\n",
    "\n",
    "# d) Selecció 2\n",
    "# Xdata = np.array(miltr.iloc[:,[0,3,6,26]])\n",
    "# Xtst = np.array(miltst.iloc[:,[1,4,7,27]])\n",
    "\n",
    "\n",
    "# e) Alltr: d + mass\n",
    "# Xdata = np.array(alltr.iloc[:,[1,4,7,27,28]])\n",
    "# Xtst = np.array(alltst.iloc[:,[1,4,7,27,28]])\n",
    "\n",
    "# f) Alltr: LL \n",
    "# Xdata = np.array(alltr.loc[:,[\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\n",
    "#                               \"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\"]])\n",
    "# Xtst = np.array(alltst.loc[:,[\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\"\n",
    "#                               ,\"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\"]])\n",
    "\n",
    "# g) Alltr: LL + HL \n",
    "# Xdata = np.array(alltr.loc[:,[\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\n",
    "#                               \"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\",\"f22\",\"f23\",\"f24\",\"f25\",\"f26\",\"mass\"]])\n",
    "# Xtst = np.array(alltst.loc[:,[\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\",\"f12\",\n",
    "#                               \"f13\",\"f14\",\"f15\",\"f16\",\"f17\",\"f18\",\"f19\",\"f20\",\"f21\",\"f22\",\"f23\",\"f24\",\"f25\",\"f26\",\"mass\"]])\n",
    "\n",
    "# h) Alltr: 3 5 6 26 27\n",
    "# Xdata = np.array(alltr.iloc[:,[3,5,6,26,27]])\n",
    "# Xtst = np.array(alltst.iloc[:,[3,5,6,26,27]])\n",
    "\n",
    "# i) Alltr: 0 26 27\n",
    "Xdata = np.array(alltr.loc[:,[\"f0\",\"f26\",\"mass\"]])\n",
    "Xtst = np.array(alltst.loc[:,[\"f0\",\"f26\",\"mass\"]])\n",
    "\n",
    "\n",
    "\n",
    "# Part 2: Càlcul DT\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "startTime = time.time()\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 4)\n",
    "clf = clf.fit(Xdata, Ydata)\n",
    "\n",
    "temps = time.time() - startTime\n",
    "\n",
    "print(temps)\n",
    "\n",
    "\n",
    "# Part 3: Avaluació DT\n",
    "acc = clf.score(Xtst, Ytst)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0bf4f8-6beb-426a-8037-1523e268b4f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Precisions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72043d5-b431-4103-902e-b7fc728ffdf6",
   "metadata": {},
   "source": [
    "- miltr LL, max_depth = 5, miltst:         0.54265\n",
    "\n",
    "- miltr LL+HL, max_depth = 5, miltst:      0.68485 (temps = 202 s)\n",
    "- miltr LL+HL, max_depth = 8, miltst:      0.65410 (temps = 350 s)\n",
    "- miltr LL+HL, max_depth = 4, miltst:      0.72376 (temps = 157 s)\n",
    "- miltr LL+HL, max_depth = 3, miltst:      0.74780 (temps = 115 s) !!\n",
    "- miltr LL+HL, max_depth = 2, miltst:      0.57717 (temps =  75 s)\n",
    "\n",
    "- miltr selecció 1, max_depth = 2, miltst: 0.66136 (temps = 20 s)\n",
    "- miltr selecció 1, max_depth = 3, miltst: 0.66163 (temps = 29 s)\n",
    "- miltr selecció 1, max_depth = 4, miltst: 0.66231 (temps = 39 s)\n",
    "\n",
    "- miltr selecció 2, max_depth = 3, miltst: 0.90009 (temps = 21 s) !! Seleccione aquestes variables pq són les que empra en t = 115 \n",
    "- miltr selecció 2, max_depth = 4, miltst: 0.90504 (temps = 28 s)\n",
    "- miltr selecció 2, max_depth = 2, miltst: 0.89052 (temps = 14 s)\n",
    "- miltr selecció 2, max_depth = 5, miltst: 0.90687 (temps = 36 s)\n",
    "- miltr selecció 2, max_depth = 6, miltst: 0.90724 (temps = 43 s)\n",
    "\n",
    "\n",
    "- alltr d + mass, max_depth = 3, alltst:   0.80764 (temps = 22 s)\n",
    "- alltr d + mass, max_depth = 4, alltst:   0.82198 (temps = 31 s)\n",
    "- alltr d + mass, max_depth = 2, alltst:   0.80764 (temps = 22 s)\n",
    "- alltr d + mass, max_depth = 5, alltst:   0.83335 (temps = 35 s)\n",
    "\n",
    "- alltr LL, max_depth = 8, alltst:         0.81532 (temps = 288 s)\n",
    "- alltr LL + HL, max_depth = 8, alltst:    0.84975 (temps = 360 s)\n",
    "- alltr h, max_depth = 2, alltst:          0.76904 (temps =  16 s)\n",
    "- alltr h, max_depth = 4, alltst:          0.77089 (temps =  31 s)\n",
    "- alltr i, max_depth = 4, alltst:          0.79936 (temps =  17 s)\n",
    "\n",
    "Per calcular l'error de les precisions, potser es podria plantejar dividir la mostra de test i després fer la desviació de la precisió? Quin rigor tindria?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fec389-dd04-480e-b691-0fc058e8305a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b36e7c-66c8-411b-8d30-f88e74e1116a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(Xdata)\n",
    "# print(Ydata)\n",
    "# print(Xtst)\n",
    "# print(miltr)\n",
    "# print(miltst)\n",
    "\n",
    "# Xdata = np.array(miltr.iloc[:,[0,3,6,26]])\n",
    "# Xtst = np.array(miltst.iloc[:,[1,4,7,27]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c313a42b-f6fa-4996-8af2-94035f0671a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Càlcul i avaluació completa amb accuracy + kappa + F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47134d7-7b33-44c3-977e-8664c5f5fcc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# Comprovació del mecanisme per a calcular\n",
    "# temp = np.array(alltr.loc[:,[\"f25\",\"f26\"]])\n",
    "# temp[:,0] = temp[:,0]/temp[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c993cc7d-e359-4c24-9d97-5e0e3249660b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part 1: definim Ydata, Ytst per a tots i Xdata, Xtst per a cada cas \n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "startTime = time.time()\n",
    "\n",
    "# Ydata = np.array(miltr.index)\n",
    "# Ytst = np.array(miltst.iloc[:,0])\n",
    "\n",
    "Ydata = np.array(alltr.iloc[:,[0]])\n",
    "Ytst = np.array(alltst.iloc[:,0])\n",
    "\n",
    "# d) Selecció 2\n",
    "# Xdata = np.array(miltr.iloc[:,[0,3,6,26]])\n",
    "# Xtst = np.array(miltst.iloc[:,[1,4,7,27]])\n",
    "# label = \"d\"\n",
    "\n",
    "# j) Alltr: 0 25 26 27\n",
    "# Xdata = np.array(alltr.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "# Xtst = np.array(alltst.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "# label = \"j\"\n",
    "\n",
    "# k) Alltr: HL + # label  --> Solament selecciona el mateix que j, almenys fins a depth = 5\n",
    "# Xdata = np.array(alltr.loc[:,[\"f0\",\"f22\",\"f23\",\"f24\",\"f25\",\"f26\",\"mass\"]])\n",
    "# Xtst = np.array(alltst.loc[:,[\"f0\",\"f22\",\"f23\",\"f24\",\"f25\",\"f26\",\"mass\"]])\n",
    "# label = \"k\"\n",
    "\n",
    "# l) Altres variables? Masses invariants pseudonormalitzades?\n",
    "# Xdata = np.array(alltr.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "# Xtst = np.array(alltst.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "# Xdata[:,2] = Xdata[:,2] / Xdata[:,3]\n",
    "# Xdata[:,1] = Xdata[:,1] / Xdata[:,3]\n",
    "# Xtst[:,2] = Xtst[:,2] / Xtst[:,3]\n",
    "# Xtst[:,1] = Xtst[:,1] / Xtst[:,3]\n",
    "# label = \"l\"\n",
    "\n",
    "# m) Altres variables? Masses invariants pseudonormalitzades?\n",
    "Xdata = np.array(alltr.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "Xtst = np.array(alltst.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "Xdata[:,2] = Xdata[:,2] / np.log(Xdata[:,3])\n",
    "Xdata[:,1] = Xdata[:,1] / np.log(Xdata[:,3])\n",
    "Xtst[:,2] = Xtst[:,2] / np.log(Xtst[:,3])\n",
    "Xtst[:,1] = Xtst[:,1] / np.log(Xtst[:,3])\n",
    "label = \"m\"\n",
    "# Sembla que millora molt lleugerament!?\n",
    "\n",
    "\n",
    "\n",
    "# Part 2: Càlcul DT\n",
    "\n",
    "# from sklearn import tree\n",
    "# from sklearn import metrics\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth = 7)\n",
    "clf = clf.fit(Xdata, Ydata)\n",
    "\n",
    "\n",
    "# Part 3: Avaluació DT\n",
    "Ypred = clf.predict(Xtst)\n",
    "acc = clf.score(Xtst, Ytst)\n",
    "kappa = metrics.cohen_kappa_score(Ypred,Ytst)\n",
    "F1S = metrics.f1_score(Ytst,Ypred)\n",
    "\n",
    "temps = time.time() - startTime\n",
    "\n",
    "# print(\"DT amb profunditat %i.\\nPrecisió = %f; kappa = %f; F1-Score = %f.\\nTemps d'execució = %i segons\" \n",
    "#       % (clf.get_depth(),acc,kappa,F1S,temps)) # Format agradable\n",
    "\n",
    "print(\"| %s | %i | %f | %f | %f | %i |\" % (label,clf.get_depth(),acc,kappa,F1S,temps)) # Format per copiar i pegar a la taula\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9a7198-bb7e-43c5-83da-aa8ba83285f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Taula amb els diferents resultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a863e6e6-09ee-4403-925d-103eb3a2f782",
   "metadata": {},
   "source": [
    "| labels | Max_depth |  Acc  | Kappa | F1-S | Temps (s) |\n",
    "|:------:|:---------:|:-----:|:-----:|:----:|-------|\n",
    "| *Proves amb miltr* |\n",
    "| d | 2 | 0.890521 | 0.781038 | 0.887665 | 19 |\n",
    "| d | 3 | 0.900094 | 0.800189 | 0.900821 | 25 |\n",
    "| d | 4 | 0.905037 | 0.810078 | 0.907020 | 33 |\n",
    "| d | 5 | 0.906873 | 0.813750 | 0.908726 | 41 |\n",
    "| d | 6 | 0.907243 | 0.814490 | 0.909205 | 48 |\n",
    "| *Proves amb alltr* |\n",
    "| j | 2 | 0.769049 | 0.538069 | 0.751082 | 17 |\n",
    "| j | 3 | 0.780025 | 0.560112 | 0.811145 | 22 |\n",
    "| j | 4 | 0.799363 | 0.598737 | 0.805066 | 28 |\n",
    "| j | 5 | 0.814112 | 0.628248 | 0.827549 | 35 |\n",
    "| j | 6 | 0.816163 | 0.632358 | 0.832628 | 41 |\n",
    "| j | 7 | 0.821382 | 0.642784 | 0.832045 | 51 |\n",
    "| k | 2 | 0.769049 | 0.538069 | 0.751082 | 25 |\n",
    "| k | 5 | 0.814112 | 0.628248 | 0.827549 | 58 |\n",
    "| l | 5 | 0.669295 | 0.338461 | 0.571760 | 26 |\n",
    "| m | 5 | 0.814721 | 0.629476 | 0.832802 | 39 |\n",
    "| m | 7 | 0.821215 | 0.642457 | 0.835248 | 53 |\n",
    "\n",
    "\n",
    "Dubtes 02/11:\n",
    "- Com avalue per a diferents masses? Al paper s'empra un únic resultat i s'avalua amb diferents masses per fer la taula 1?\n",
    "- Sembla que l'entrenament amb miltr és més efectiu però potser pq no cal que tinga en compte la massa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365731b0-72f0-490d-b3c4-d26944036573",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(miltr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddcf58c-f9b2-489d-acde-6af6e87f9d40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d95c04a-c4bf-4d8f-9a5a-90e27ca47026",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Repliquem Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e725e6-b8e9-403f-88cd-e0620412a8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reemprem\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None,*,value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        \n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None # Si existeix un valor, aleshores hi ha al menys un fill, per tant no és --> false\n",
    "        \n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_features=None):\n",
    "        self.min_samples_split=min_samples_split\n",
    "        self.max_depth=max_depth\n",
    "        self.n_features=n_features\n",
    "        self.root=None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1] if not self.n_features else min(X.shape[1], self.n_features)\n",
    "        self.root = self._grow_tree(X,y)\n",
    "        \n",
    "    def _grow_tree(self, X, y, depth = 0):\n",
    "        n_samples, n_feats = X.shape\n",
    "        n_labels = len(np.unique(y))\n",
    "        \n",
    "        # Check the stopping criteria\n",
    "        if (depth>=self.max_depth or n_labels == 1 or n_samples < self.min_samples_split):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "        # Si tenim el màxim de profunditat, si tenim un node pur o arribem al mínim de mostres, no crearem més\n",
    "        \n",
    "        feat_idx = np.random.choice(n_feats, self.n_features, replace = False)\n",
    "        \n",
    "        # Find the best split\n",
    "        best_feature, best_thresh = self._best_split(X, y, feat_idx) # Lloc on incloem la part aleatòria dels DT\n",
    "        \n",
    "        # Create child nodes\n",
    "        left_idxs, right_idxs = self._split(X[:,best_feature], best_thresh)\n",
    "        left = self._grow_tree(X[left_idxs,:],y[left_idxs], depth+1)\n",
    "        right = self._grow_tree(X[right_idxs,:],y[right_idxs], depth+1)\n",
    "        return Node(best_feature, best_thresh, left, right)\n",
    "        \n",
    "        \n",
    "    def _best_split(self, X, y, feat_idxs):\n",
    "        best_gain = -1\n",
    "        split_idx, split_threshold = None, None\n",
    "        \n",
    "        for feat_idx in feat_idxs:\n",
    "            X_column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_column)\n",
    "            \n",
    "            for thr in thresholds:\n",
    "                # Calculate Information gain\n",
    "                gain = self._information_gain(y, X_column, thr)\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_threshold = thr\n",
    "        \n",
    "        return split_idx, split_threshold\n",
    "    \n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        # Parent entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "        \n",
    "        # Create children\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        \n",
    "        if(len(left_idxs) == 0 or len(right_idxs) == 0):\n",
    "           return 0\n",
    "        \n",
    "        # Calculate weighted avg. entropy of children\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left_idxs), len(right_idxs)\n",
    "        e_l, e_r = self._entropy(y[left_idxs]),self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_l/n) * e_l + (n_r/n) * e_r    \n",
    "           \n",
    "        # Calculate IG\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "        \n",
    "    def _entropy(self, y):\n",
    "        uniq, inverse = np.unique(y, return_inverse=True) # Afegit per mi per poder fer el mateix amb floats en comptes d'int\n",
    "        hist = np.bincount(inverse)\n",
    "        ps = hist / len(y)\n",
    "        return -np.sum([p*np.log(p) for p in ps if p > 0])\n",
    "   \n",
    "    def _split(self, X_column, split_thresh):\n",
    "        left_idxs = np.argwhere(X_column <= split_thresh).flatten()\n",
    "        right_idxs = np.argwhere(X_column > split_thresh).flatten()\n",
    "        return left_idxs, right_idxs\n",
    "        \n",
    "        \n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        value = counter.most_common(1)[0][0] # Mirar en Logistic Regression\n",
    "        return value\n",
    "                        \n",
    "\n",
    "    def predict(self,X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "    \n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "           return node.value\n",
    "           \n",
    "        if x[node.feature] <= node.threshold:\n",
    "           return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cf983-6625-4953-82ce-331d9b72710c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from DecisionTree import DecisionTree\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "class RandomForest:\n",
    "    def __init__(self,n_trees=10,max_depth=10,min_samples_split=2,n_feature=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.n_features = n_feature\n",
    "        self.trees= []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            tree = DecisionTree(max_depth = self.max_depth,\n",
    "                         min_samples_split = self.min_samples_split,\n",
    "                         n_features = self.n_features)\n",
    "            X_sample, y_sample = self._bootstrap_samples(X,y)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            \n",
    "    def _bootstrap_samples(self,X,y):\n",
    "        n_samples = X.shape[0]\n",
    "        idxs = np.random.choice(n_samples,n_samples, replace = True)\n",
    "        return X[idxs], y[idxs]\n",
    "    \n",
    "    def _most_common_label(self,y):\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees]) \n",
    "        # amb açò, tindríem una llista de n llistes, on cada llista és el conjunt de prediccions del n-èsim tree\n",
    "        # volem tindre una llista de n llistes, on la llista n conté les prediccions de cada tree per a l'esdeveniment n-èsim\n",
    "        tree_preds = np.swapaxes(predictions,0,1) # Aquesta funció de np fa precisament açò!\n",
    "        predictions = np.array([self._most_common_label(pred) for pred in tree_preds])\n",
    "        return predictions\n",
    "    \n",
    "# Prou senzill pq es basa en DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300152a3-1fd6-4c93-bf21-16ccafe46083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "# from RandomForest import RandomForest\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.2, random_state = 1234\n",
    ")\n",
    "\n",
    "def accuracy(y_true,y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "clf = RandomForest()\n",
    "clf.fit(X_train,y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "acc = accuracy(y_test,predictions)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508767c7-6e60-48f5-899b-8ec66d60928d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del(acc, predictions, clf, data, X, y, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a54aa5-8aba-45a9-a211-5b47e4e297e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Noves llibreries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e026344-a15f-43eb-9984-8da7994cedd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046b2fd8-b0c1-4cf3-87fc-6fbddada6d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conda update jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5775f2-a46c-4c60-add3-9083ec847ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instal·lem altres paquets (prerequisits)\n",
    "# install -c anaconda python-graphviz\n",
    "# install -c anaconda pydot\n",
    "\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} python-graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575b00e-ce3e-49d2-8c34-01c1c8ab52c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install graphviz # Sembla haver funcionat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951aba5f-5630-4518-baed-b84e65596078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list # Comprova la llista de llibreries instal·lades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10430fc1-8827-485c-b57f-2d2f2c279e9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Random Forest - sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a236c1-05f4-4442-95df-7ca3f624a845",
   "metadata": {},
   "source": [
    "Càrrega de llibreries\n",
    "https://www.datacamp.com/tutorial/random-forests-classifier-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e50536-50d1-4664-b324-6e63ab41386b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf53c6d-43ae-48ea-9592-359301259281",
   "metadata": {
    "tags": []
   },
   "source": [
    "Repetim ara amb RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c468741-6b57-4a12-806a-f36108d8dc91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part 1: definim Ydata, Ytst per a tots i Xdata, Xtst per a cada cas \n",
    "startTime = time.time()\n",
    "\n",
    "Ydata = np.array(miltr.index)\n",
    "Ytst = np.array(miltst.iloc[:,0])\n",
    "\n",
    "# Ydata = alltr.iloc[:,0]\n",
    "# Ytst = alltst.iloc[:,0]\n",
    "\n",
    "# d) Selecció 2\n",
    "Xdata = np.array(miltr.iloc[:,[0,3,6,26]])\n",
    "Xtst = np.array(miltst.iloc[:,[1,4,7,27]])\n",
    "label = \"d\"\n",
    "\n",
    "# j) Alltr: 0 25 26 27\n",
    "# Xdata = np.array(alltr.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "# Xtst = np.array(alltst.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "# label = \"j\"\n",
    "\n",
    "# j2) Alltr: 0 25 26 27\n",
    "# Xdata = alltr.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]]\n",
    "# Xtst = alltst.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]]\n",
    "# label = \"j2\"\n",
    "\n",
    "\n",
    "# Part 2: càlcul RF\n",
    "# Create a random forest classifier\n",
    "max_depth = 5\n",
    "n_estimators = 5\n",
    "rf = RandomForestClassifier(max_depth = max_depth,n_estimators = n_estimators)\n",
    "rf.fit(Xdata, Ydata)\n",
    "\n",
    "       \n",
    "# Part 3: avaluació RF\n",
    "Ypred = rf.predict(Xtst)\n",
    "acc = accuracy_score(Ytst,Ypred)\n",
    "kappa = metrics.cohen_kappa_score(Ypred,Ytst)\n",
    "F1S = metrics.f1_score(Ytst,Ypred)\n",
    "temps = time.time() - startTime\n",
    "\n",
    "# print(\"RT amb profunditat %i.\\nPrecisió = %f; kappa = %f; F1-Score = %f.\\nTemps d'execució = %i segons\" \n",
    "#       % (max_depth,acc,kappa,F1S,temps)) # Format agradable\n",
    "\n",
    "print(\"| %s | %i | %i | %f | %f | %f | %i |\" % (label,max_depth,n_estimators,acc,kappa,F1S,temps)) # Format per copiar i pegar a la taula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51667b43-29f3-440e-9666-dded401d2d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(alltr.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117473d9-b9be-408f-8901-acdff1b9ce1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0496f1-4558-4804-b35c-c756c21b0005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prova = alltr.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]]\n",
    "for i in range(3):\n",
    "    tree = rf.estimators_[i]\n",
    "    data = export_graphviz(tree,\n",
    "                               feature_names=prova.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=3, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(data)\n",
    "    display(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb3aa4-f899-4e99-805f-dca08168e4e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Resultats Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46f0c0-8b46-4271-8451-3b6036c6c15a",
   "metadata": {},
   "source": [
    "| labels | Max_depth | n_estimators |  Acc  | Kappa | F1-S | Temps (s) |\n",
    "|:------:|:---------:|:-----:|:-----:|:----:|:-----:|-------|\n",
    "| *Proves amb miltr* |\n",
    "| d | 5 | 5 | 0.907114 | 0.814232 | 0.908994 | 107 |\n",
    "| d | 3 | 6 | 0.900202 | 0.800404 | 0.900286 | 80 |\n",
    "| d | 3 | 10 | 0.904306 | 0.808612 | 0.904545 | 130 |\n",
    "| *Proves amb alltr* |\n",
    "| j | 10 | 10 | 0.823783 | 0.647591 | 0.836971 | 331 |\n",
    "| j | 7 | 5 | 0.819847 | 0.639717 | 0.832060 | 128 |\n",
    "| j | 5 | 5 | 0.805153 | 0.610320 | 0.812224 | 93 |\n",
    "| j | 3 | 10 | 0.786887 | 0.573767 | 0.782951 | 105 |\n",
    "| j2 | 5 | 5 | 0.804870 | 0.609750 | 0.810402 | 80 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc594019-a35e-4a0e-8f91-6a89bbab280b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### RandomizedSearchCV?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c7fa03-6074-4c19-be36-6822671175c4",
   "metadata": {},
   "source": [
    "El mateix, però ara amb `RandomizedSearchCV`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca360266-000f-415f-ba85-5f4d05d888f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Part 1: definim Ydata, Ytst per a tots i Xdata, Xtst per a cada cas ----------\n",
    "startTime = time.time()\n",
    "\n",
    "# Ydata = np.array(miltr.index)\n",
    "# Ytst = np.array(miltst.iloc[:,0])\n",
    "\n",
    "Ydata = np.array(alltr.iloc[:,0])\n",
    "Ytst = np.array(alltst.iloc[:,0])\n",
    "\n",
    "# d) Selecció 2\n",
    "# Xdata = np.array(miltr.iloc[:,[0,3,6,26]])\n",
    "# Xtst = np.array(miltst.iloc[:,[1,4,7,27]])\n",
    "# label = \"d\"\n",
    "\n",
    "# j) Alltr: 0 25 26 27\n",
    "Xdata = np.array(alltr.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "Xtst = np.array(alltst.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "label = \"j\"\n",
    "\n",
    "\n",
    "\n",
    "# Part 2: càlcul RF aleatoritzat\n",
    "rf = RandomForestClassifier()\n",
    "param_dist = {'n_estimators': randint(1,20),\n",
    "         'max_depth': randint(1,5)} # Paràmetres\n",
    "# Use random search to find the best hyperparameters\n",
    "rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=5, \n",
    "                                 cv=5)\n",
    "rand_search.fit(Xdata,Ydata)\n",
    "\n",
    "\n",
    "\n",
    "# Part 3: avaluació RF\n",
    "Ypred = rand_search.predict(Xtst)\n",
    "acc = accuracy_score(Ytst,Ypred)\n",
    "kappa = metrics.cohen_kappa_score(Ypred,Ytst)\n",
    "F1S = metrics.f1_score(Ytst,Ypred)\n",
    "temps = time.time() - startTime\n",
    "\n",
    "# print(\"RT amb profunditat %i.\\nPrecisió = %f; kappa = %f; F1-Score = %f.\\nTemps d'execució = %i segons\" \n",
    "#       % (max_depth,acc,kappa,F1S,temps)) # Format agradable\n",
    "\n",
    "print(\"| %s | %i | %i | %f | %f | %f | %i |\" % (label,param_dist.get(\"max_depth\"),param_dist.get(n_estimators),acc,kappa,F1S,temps)) # Format per copiar i pegar a la taula\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec678ae-2f2d-4ade-9cad-acef9ab7e37f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(\"| %s | %i | %i | %f | %f | %f | %i |\" % (label,param_dist.get(\"max_depth\"),param_dist.get(n_estimators),acc,kappa,F1S,temps)) # Format per copiar i pegar a la taula\n",
    "print(randint(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa8da56-6f29-422a-a4ea-87b8468e9e5f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Resultats Taula RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99972c86-18da-403c-9960-2da9b8bb97ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "| labels | Max_depth | n_estimators |  Acc  | Kappa | F1-S | Temps (s) |\n",
    "|:------:|:---------:|:-----:|:-----:|:----:|:-----:|-------|\n",
    "| *Proves amb miltr* |\n",
    "||\n",
    "| *Proves amb alltr* |\n",
    "||"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b233c599-bea0-4ed0-818d-cc3b892757ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f0483b-2fee-44eb-9d2b-4e1e0ded6c98",
   "metadata": {},
   "source": [
    "Directament amb sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe298f-3169-4b89-b448-6b052a55d336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import datasets\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc6bf2c-c0f2-4e78-a94e-2aa565788254",
   "metadata": {},
   "source": [
    "De nou, emprem pràcticament el mateix codi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c10141-2820-45cb-b137-bb34bca46581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# Part 1: definim Ydata, Ytst per a tots i Xdata, Xtst per a cada cas \n",
    "startTime = time.time()\n",
    "\n",
    "Ydata = np.array(miltr.index)\n",
    "Ytst = np.array(miltst.iloc[:,0])\n",
    "\n",
    "# Ydata = np.array(alltr.iloc[:,0])\n",
    "# Ytst = np.array(alltst.iloc[:,0])\n",
    "\n",
    "# d) Selecció 2\n",
    "Xdata = np.array(miltr.iloc[:,[0,3,6,26]])\n",
    "Xtst = np.array(miltst.iloc[:,[1,4,7,27]])\n",
    "label = \"d\"\n",
    "\n",
    "# j) Alltr: 0 25 26 27\n",
    "# Xdata = np.array(alltr.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "# Xtst = np.array(alltst.loc[:,[\"f0\",\"f25\",\"f26\",\"mass\"]])\n",
    "# label = \"j\"\n",
    "\n",
    "\n",
    "# Part 2: càlcul AdaBoost\n",
    "# Create an AdaBoost classifier\n",
    "n_estimators = 10\n",
    "learning_rate = 1\n",
    "rf = AdaBoostClassifier(n_estimators = n_estimators, learning_rate = learning_rate)\n",
    "rf.fit(Xdata, Ydata)\n",
    "\n",
    "       \n",
    "# Part 3: avaluació AdaBoost\n",
    "Ypred = rf.predict(Xtst)\n",
    "acc = accuracy_score(Ytst,Ypred)\n",
    "kappa = metrics.cohen_kappa_score(Ypred,Ytst)\n",
    "F1S = metrics.f1_score(Ytst,Ypred)\n",
    "temps = time.time() - startTime\n",
    "\n",
    "# print(\"RT amb profunditat %i.\\nPrecisió = %f; kappa = %f; F1-Score = %f.\\nTemps d'execució = %i segons\" \n",
    "#       % (max_depth,acc,kappa,F1S,temps)) # Format agradable\n",
    "\n",
    "print(\"| %s | %.2f | %i | %f | %f | %f | %i |\" % (label,learning_rate,n_estimators,acc,kappa,F1S,temps)) # Format per copiar i pegar a la taula\n",
    "Audio(sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9ad3d-8b31-4a5b-a951-ff4f6b11b541",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Resultats Taula AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e3073-bb39-4355-8ccd-d9cc0ed105ae",
   "metadata": {},
   "source": [
    "| labels | learning_rate | n_estimators |  Acc  | Kappa | F1-S | Temps (s) |\n",
    "|:------:|:---------:|:-----:|:-----:|:----:|:-----:|-------|\n",
    "| *Proves amb miltr* |\n",
    "| d | 1.00 | 10 | 0.900278 | 0.800557 | 0.901410 | 106 |\n",
    "| *Proves amb alltr* |\n",
    "| j | 1.000 | 10 | 0.786525 | 0.573037 | 0.779163 | 97 |\n",
    "| j | 2.000 | 10 | 0.230951 | -0.538002 | 0.282435 | 93 |\n",
    "| j | 0.500 | 10 | 0.782417 | 0.564828 | 0.778332 | 100 |\n",
    "| j | 0.500 | 20 | 0.788068 | 0.576123 | 0.780117 | 241 |\n",
    "| j | 1.000 | 100 | 0.792516 | 0.585020 | 0.785506 | 962 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31ed49-1d0c-41bb-8ba3-8d52c0e7f613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adf79ff4-26dd-46ec-9925-90aa48bbf6f7",
   "metadata": {},
   "source": [
    "# **Tercera sessió: masses invariants, dispersió mesuradors, representació DT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e3851-2ce8-4c7d-b639-394a998971cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Càlcul de la massa invariant en funció dels pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59737c61-560a-4d00-ae80-35fb2c0b7e05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Experimentació inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55942c09-e5fb-4b97-8841-60dec737d737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alltr = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quint\\TFG\\RstudioPython\\Dades\\Normal\\all_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc99b1a-bf00-4b2c-a6f2-93b4d29eecd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alltr.columns = [\"Signal\",\"l_pt\",\"l_eta\",\"l_phi\",\"MET\",\"M_phi\",\"njets\",\"pt1\",\"eta1\",\"phi1\",\"b1\",\"pt2\",\"eta2\",\"phi2\",\"b2\",\n",
    "                 \"pt3\",\"eta3\",\"phi3\",\"b3\",\"pt4\",\"eta4\",\"phi4\",\"b4\",\"m_jj\",\"m_jjj\",\"m_lv\",\"m_jlv\",\"m_wwbb\",\"mass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3007fe4-0b5f-4c58-8413-e18431299a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(alltr.loc[:,[\"b1\",\"b2\",\"b3\",\"b4\"]]) # --> 10,14,18,22\n",
    "# alltr.iloc[:,[10,14,18,22]] = alltr.iloc[:,[10,14,18,22]]\n",
    "# print(alltr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b7f65-ac29-4477-9d6c-30b3cc57e5e4",
   "metadata": {},
   "source": [
    "Primer anem a desnormalitzar els btag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9b3e3-128d-4ba5-94be-ca9d3aca3e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "btags = alltr.loc[:,[\"b1\",\"b2\",\"b3\",\"b4\",\"mass\"]]\n",
    "btags.iloc[:,0] = (btags.iloc[:,0] - btags.iloc[4,0]) / (btags.iloc[0,0] - btags.iloc[4,0])\n",
    "btags.iloc[:,1] = (btags.iloc[:,1] - btags.iloc[0,1]) / (btags.iloc[3,1] - btags.iloc[0,1])\n",
    "btags.iloc[:,2] = (btags.iloc[:,2] - btags.iloc[0,2]) / (btags.iloc[1,2] - btags.iloc[0,2])\n",
    "btags.iloc[:,3] = (btags.iloc[:,3] - btags.iloc[1,3]) / (btags.iloc[0,3] - btags.iloc[1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d83f6-0b02-4bf1-a2da-9ba3b179ba47",
   "metadata": {
    "tags": []
   },
   "source": [
    "Ara seleccionem solament els events amb sum(bi) = 2. Primerament, creem una nova columna que sume els btag totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205e12d-9dbd-43f7-a5a4-d7530b1dcac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "btags.insert(4,\"btotal\",(btags.iloc[:,0]+btags.iloc[:,1]+btags.iloc[:,2]+btags.iloc[:,3]),True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee4e83-d28e-41d0-857f-c893b4a995ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "I ara seleccionem solament aquells esdeveniments que tenen btotal == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa199f66-e981-430b-a9b7-193046d51bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "esdev = btags[btags[\"btotal\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50161c73-590f-491f-bf1d-aeda41e474ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(btags)\n",
    "print(esdev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b913d80b-b2df-43b1-b70a-70c332e320ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Ara de nou, però sense separar únicament els btags i tot de colp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5e0f04-26a2-411b-a855-4d421c5f693d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alltr = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quint\\TFG\\RstudioPython\\Dades\\Normal\\all_train.csv\")\n",
    "alltr.columns = [\"Signal\",\"l_pt\",\"l_eta\",\"l_phi\",\"MET\",\"M_phi\",\"njets\",\"pt1\",\"eta1\",\"phi1\",\"b1\",\"pt2\",\"eta2\",\"phi2\",\"b2\",\n",
    "                 \"pt3\",\"eta3\",\"phi3\",\"b3\",\"pt4\",\"eta4\",\"phi4\",\"b4\",\"m_jj\",\"m_jjj\",\"m_lv\",\"m_jlv\",\"m_wwbb\",\"mass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e0b54-c4e6-4bc0-a7c0-f777ff69a747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Executar únicament una vegada!\n",
    "alltr.iloc[:,10] = (alltr.iloc[:,10] - alltr.iloc[4,10]) / (alltr.iloc[0,10] - alltr.iloc[4,10])\n",
    "alltr.iloc[:,14] = (alltr.iloc[:,14] - alltr.iloc[0,14]) / (alltr.iloc[3,14] - alltr.iloc[0,14])\n",
    "alltr.iloc[:,18] = (alltr.iloc[:,18] - alltr.iloc[0,18]) / (alltr.iloc[1,18] - alltr.iloc[0,18])\n",
    "alltr.iloc[:,22] = (alltr.iloc[:,22] - alltr.iloc[1,22]) / (alltr.iloc[0,22] - alltr.iloc[1,22])\n",
    "alltr.insert(0,\"btotal\",(alltr.iloc[:,10]+alltr.iloc[:,14]+alltr.iloc[:,18]+alltr.iloc[:,22]),True)\n",
    "print(alltr.loc[:,[\"btotal\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd77849-b1bb-4e13-8118-834a594dba32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "someTr = alltr[alltr[\"btotal\"] == 2]\n",
    "someTr.drop('btotal', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bf829e-cb21-4e2d-8825-7cbf739eebeb",
   "metadata": {},
   "source": [
    "Ara tenim un DataFrame anomenat someTr amb els btags desnormalitzats i solament aquells esdeveniments on dos dels jets son b. El btotal l'esborrem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf1ef8-4450-476f-b7c8-d9788b04e722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(someTr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c7b0a-b961-49f3-b60d-1bf1687e031a",
   "metadata": {},
   "source": [
    "Creem un nou dataframe `vectors` seleccionant els únicament els NO B. La cel·la següent selecciona els SÍ B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac3392-9af3-4fe9-983e-9c771835efe5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vectors = pd.DataFrame(np.zeros([6_052_999,7]))\n",
    "# vectors.columns = [\"p1\",\"eta1\",\"phi1\",\"p2\",\"eta2\",\"phi2\",\"mass\"]\n",
    "# vectors.loc[:,\"mass\"] = someTr.loc[:,\"mass\"]\n",
    "\n",
    "# for i in range(6_052_999):\n",
    "#     if someTr.iloc[i,10] and someTr.iloc[i,14]:\n",
    "#         vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,11,12,13]]\n",
    "#     elif someTr.iloc[i,10] and someTr.iloc[i,18]:\n",
    "#         vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,15,16,17]]\n",
    "#     elif someTr.iloc[i,10] and someTr.iloc[i,22]:\n",
    "#         vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,19,20,21]]\n",
    "#     elif someTr.iloc[i,10] and someTr.iloc[i,18]:\n",
    "#         vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[11,12,13,15,16,17]]\n",
    "#     elif someTr.iloc[i,14] and someTr.iloc[i,22]:\n",
    "#         vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[11,12,13,19,20,21]]\n",
    "#     elif someTr.iloc[i,18] and someTr.iloc[i,22]:\n",
    "#         vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[15,16,17,19,20,21]]\n",
    "\n",
    "# print(vectors)\n",
    "\n",
    "# 1576 segons --> 26 min 16 segons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c3c9c-e7cd-445f-8d23-45f20d45514d",
   "metadata": {},
   "source": [
    "Creem un nou dataframe `vectors` seleccionant els únicament els NO B (hem copiat i pegat el codi i permutat True-False l'assignació)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45b6c0-9b2f-470d-bc45-79a234a2d665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectors = pd.DataFrame(np.zeros([6_052_999,7]))\n",
    "vectors.columns = [\"p1\",\"eta1\",\"phi1\",\"p2\",\"eta2\",\"phi2\",\"mass\"]\n",
    "vectors.loc[:,\"mass\"] = someTr.loc[:,\"mass\"]\n",
    "\n",
    "for i in range(6_052_999):\n",
    "    if someTr.iloc[i,10] and someTr.iloc[i,14]:\n",
    "        vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[15,16,17,19,20,21]]\n",
    "    elif someTr.iloc[i,10] and someTr.iloc[i,18]:\n",
    "        vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[11,12,13,19,20,21]]\n",
    "    elif someTr.iloc[i,10] and someTr.iloc[i,22]:\n",
    "        vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[11,12,13,15,16,17]]\n",
    "    elif someTr.iloc[i,10] and someTr.iloc[i,18]:\n",
    "        vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,19,20,21]]\n",
    "    elif someTr.iloc[i,14] and someTr.iloc[i,22]:\n",
    "        vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,15,16,17]]\n",
    "    elif someTr.iloc[i,18] and someTr.iloc[i,22]:\n",
    "        vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,11,12,13]]\n",
    "\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaca348c-79e3-40fb-87a6-ed5c00be75f8",
   "metadata": {},
   "source": [
    "Segon mecanisme, entenc que són menys comprovacions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26fb9e8-56c3-4ad3-9af0-7950761b058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.DataFrame(np.zeros([6_052_999,7]))\n",
    "vectors.columns = [\"p1\",\"eta1\",\"phi1\",\"p2\",\"eta2\",\"phi2\",\"mass\"]\n",
    "vectors.loc[:,\"mass\"] = someTr.loc[:,\"mass\"]\n",
    "\n",
    "for i in range(6_052_999):\n",
    "    if someTr.iloc[i,10]:\n",
    "        if someTr.iloc[i,14]:\n",
    "            vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[15,16,17,19,20,21]]\n",
    "        elif someTr.iloc[i,18]:\n",
    "            vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[11,12,13,19,20,21]]\n",
    "        elif someTr.iloc[i,22]:\n",
    "            vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[11,12,13,15,16,17]]\n",
    "    elif someTr.iloc[i,14]:\n",
    "        if someTr.iloc[i,18]:\n",
    "            vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,19,20,21]]\n",
    "        if someTr.iloc[i,22]:\n",
    "            vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,15,16,17]]\n",
    "    else:\n",
    "        vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,11,12,13]]\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a49420-1857-4820-aaa1-f6eaa2cf8de4",
   "metadata": {},
   "source": [
    "Desfem el canvi de la pseudorapidity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d806037-8893-4df5-9ae6-0493a6c25487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectors.loc[:,[\"eta1\",\"eta2\"]] = 2*(((-1*vectors.loc[:,[\"eta1\",\"eta2\"]]).apply(np.exp)).apply(np.arctan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1940e5cb-0a38-4883-a54c-bda01d637646",
   "metadata": {},
   "source": [
    "Ara calculem els productes escalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54903802-08ea-44f2-8fd1-10351a1699ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m_jj = pd.DataFrame(np.zeros([6_052_999,0]))\n",
    "\n",
    "# Fòrmula: 2*p1*p2*(1 - sin(phi1)*sin(phi2)*cos(theta1-theta2) - cos(phi1)*cos(phi2))\n",
    "# La partim en tres trossos: 1 - sin..., -cos, 2*p1*p2*.\n",
    "\n",
    "m_jj = 1 - vectors.loc[:,\"phi1\"].apply(np.sin) * vectors.loc[:,\"phi2\"].apply(np.sin) * (vectors.loc[:,\"eta1\"] - vectors.loc[:,\"eta2\"]).apply(np.cos)\n",
    "m_jj = m_jj - vectors.loc[:,\"phi1\"].apply(np.cos) * vectors.loc[:,\"phi2\"].apply(np.cos)\n",
    "m_jj = 2*vectors.loc[:,\"p1\"] * vectors.loc[:,\"p2\"] * m_jj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f1e87-c9a0-4ef2-bee3-51a4cec3a216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81af00d-35e5-41b3-b937-fb46a73b2f1e",
   "metadata": {},
   "source": [
    "Guardem vectors en un dataframe per estalviar temps de computació"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75794d10-0b6d-4d57-8cce-2bc181324674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectors.to_csv(\"vectors.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0e07ba-6597-4d3d-a10c-880f34de348b",
   "metadata": {},
   "source": [
    "Ara intentem representar els dos histogrames en el mateix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f8a97-db1c-478d-a0fe-3245686af9b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An \"interface\" to matplotlib.axes.Axes.hist() method\n",
    "n, bins, patches = plt.hist(x=alltr.loc[:,\"pt1\"], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Massa_jj')\n",
    "plt.ylabel('Freqüència')\n",
    "plt.title('Freqüència de la massa invariant dels dos jets no b')\n",
    "# maxfreq = n.max()\n",
    "# Set a clean upper y-axis limit.\n",
    "# plt.ylim(ymax=np.ceil(maxfreq / 10) * 10 if maxfreq % 10 else maxfreq + 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f4f178-c88c-4084-b704-5000a13d00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "dist.plot.kde(ax=ax, legend=False, title='Histogram: A vs. B')\n",
    "dist.plot.hist(density=True, ax=ax)\n",
    "ax.set_ylabel('Probability')\n",
    "ax.grid(axis='y')\n",
    "ax.set_facecolor('#d8dcd6')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4d036b-83b9-4dda-b5a5-61066f0b17b4",
   "metadata": {},
   "source": [
    "## Una vegada més, però hem de carregar les dades no normalitzades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e2b83-8b32-42b3-9e49-bd5ce2e25b24",
   "metadata": {},
   "source": [
    "Experimentació amb la càrrega de dades nonorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c892514-8706-4c67-906f-3e565a29f9c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nonorm1 = pd.DataFrame(np.loadtxt(\"D:/OneDrive/Universitat/5. Quint/TFG/RstudioPython/Dades/NoNormalTrue/xttbar_m1000_aug17.txt\"))\n",
    "# nonorm2 = pd.DataFrame(np.loadtxt(\"D:/OneDrive/Universitat/5. Quint/TFG/RstudioPython/Dades/NoNormalTrue/xttbar_m1000_aug4.txt\"))\n",
    "# nonorm = pd.concat([nonorm1,nonorm2])\n",
    "# del(nonorm1,nonorm2)\n",
    "nonorm.columns = [\"l_pt\",\"l_eta\",\"l_phi\",\"MET\",\"M_phi\",\"njets\",\"pt1\",\"eta1\",\"phi1\",\"b1\",\"pt2\",\"eta2\",\"phi2\",\"b2\",\n",
    "                 \"pt3\",\"eta3\",\"phi3\",\"b3\",\"pt4\",\"eta4\",\"phi4\",\"b4\",\"m_jj\",\"m_jjj\",\"m_lv\",\"m_jlv\",\"m_wwbb\"]\n",
    "# nonorm.insert(0,\"btotal\",pd.DataFrame(np.zeros(len(nonorm))),True)\n",
    "print(nonorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "aa90382d-2954-469d-9d7b-a9969f99131a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nonorm.to_csv(\"nonorm1000.csv\", sep=',', index=False)\n",
    "# nonorm = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quint\\TFG\\RstudioPython\\nonorm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5dfe9edb-3f1f-4f55-9c1e-37abc58191a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         btotal      l_pt     l_eta     l_phi       MET     M_phi  njets  \\\n",
      "0           0.0   67.1586 -0.401861 -2.001390   74.6864 -2.368410    5.0   \n",
      "1           0.0   60.4229  0.120294 -1.130370   50.0822  0.113770    6.0   \n",
      "2           0.0   89.6661 -0.094363  2.765500   50.2144 -0.536717    8.0   \n",
      "3           0.0  341.3370 -0.848825  1.686060  108.8430  2.199950    5.0   \n",
      "4           0.0   51.0312  0.857422  2.299890   45.8390 -0.576509    7.0   \n",
      "...         ...       ...       ...       ...       ...       ...    ...   \n",
      "1469835     0.0  255.9540  0.150282 -3.007670   32.1345 -1.279370    5.0   \n",
      "1469836     0.0   60.0199 -1.943500 -1.823890  235.4770 -0.751269    4.0   \n",
      "1469837     0.0  230.8800 -0.876823  0.383096  114.3140  0.690178    4.0   \n",
      "1469838     0.0  203.9840 -0.364390 -0.382846   23.1379  1.690890    5.0   \n",
      "1469839     0.0   71.8701 -1.818900  1.532800   69.6196  2.154130    4.0   \n",
      "\n",
      "             pt1      eta1      phi1  ...   b3       pt4      eta4      phi4  \\\n",
      "0        362.653 -0.133846  2.746010  ...  1.0   39.6614 -0.992886  0.617717   \n",
      "1        335.215  0.295992 -2.196610  ...  0.0  105.6460  2.586300  1.974340   \n",
      "2        502.435 -0.244413 -1.073380  ...  0.0  167.3190  2.773380  0.940980   \n",
      "3        344.545 -1.443150 -1.656990  ...  1.0   53.2059 -0.048038  1.652710   \n",
      "4        170.579 -1.572120 -1.948680  ...  0.0   76.6896 -2.180090 -1.588020   \n",
      "...          ...       ...       ...  ...  ...       ...       ...       ...   \n",
      "1469835  198.185  0.209728  0.006897  ...  1.0  115.7750  2.780930  0.810238   \n",
      "1469836  417.286 -1.121920  2.311920  ...  1.0   42.1538 -0.810662  1.529180   \n",
      "1469837  308.404 -0.949504 -2.896630  ...  0.0   35.6245  2.021120 -1.871000   \n",
      "1469838  216.505  0.283796  0.349880  ...  0.0   62.4904  1.236190 -1.765300   \n",
      "1469839  352.464 -0.306000 -1.166630  ...  0.0   70.0334 -1.099670 -1.265080   \n",
      "\n",
      "          b4      m_jj    m_jjj      m_lv    m_jlv    m_wwbb  \n",
      "0        0.0   81.9592  163.925   81.8644  377.541  1000.460  \n",
      "1        0.0  292.7400  423.015   80.9355  126.007  1328.430  \n",
      "2        0.0   34.7412  161.451  133.7700  491.952  2860.770  \n",
      "3        1.0   69.6755  195.056   97.9658  342.877  1412.560  \n",
      "4        1.0  108.4270  172.425   95.8825  221.799   959.831  \n",
      "...      ...       ...      ...       ...      ...       ...  \n",
      "1469835  0.0  204.5690  308.385  137.9500  208.469  1332.140  \n",
      "1469836  0.0  137.3320  220.611  121.4930  757.493  1047.980  \n",
      "1469837  0.0  235.9320  423.734   79.1297  656.878  1120.940  \n",
      "1469838  0.0   73.2696  164.535  118.2810  256.302   889.006  \n",
      "1469839  1.0  589.6520  706.814   80.0058  528.259  1316.560  \n",
      "\n",
      "[7255944 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "print(nonorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed6427-7aea-4384-a275-548035caec01",
   "metadata": {},
   "source": [
    "Càrrega de dades, càlcul de btotal. Emprarem únicament les dades amb m = 1000 GeV de moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5eb78802-2413-4d36-a6d4-d402879f3f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nonorm = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quint\\TFG\\RstudioPython\\nonorm.csv\")\n",
    "\n",
    "nonorm.iloc[:,0] = (nonorm.iloc[:,10]+nonorm.iloc[:,14]+nonorm.iloc[:,18]+nonorm.iloc[:,22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274c371-2a59-4e64-9a51-4d6ecde6dd09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(nonorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14b36b5-8103-4e62-8a92-b608b4be44bb",
   "metadata": {},
   "source": [
    "Selecció d'únicament els esdeveniments amb dos bjets i creació d'un nou df `vectors` que recull els jets no b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd9b0e-20e6-4d40-a703-146e8ee67647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "someTr = nonorm[nonorm[\"btotal\"] == 2]\n",
    "n_esdev = len(someTr)\n",
    "\n",
    "vectors = pd.DataFrame(np.zeros([n_esdev,6]))\n",
    "vectors.columns = [\"p1\",\"eta1\",\"phi1\",\"p2\",\"eta2\",\"phi2\"]\n",
    "\n",
    "for i in range(n_esdev):\n",
    "    if someTr.iloc[i,10]:\n",
    "        if someTr.iloc[i,14]:\n",
    "            vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[15,16,17,19,20,21]]\n",
    "        elif someTr.iloc[i,18]:\n",
    "            vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[11,12,13,19,20,21]]\n",
    "        elif someTr.iloc[i,22]:\n",
    "            vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[11,12,13,15,16,17]]\n",
    "    elif someTr.iloc[i,14]:\n",
    "        if someTr.iloc[i,18]:\n",
    "            vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,19,20,21]]\n",
    "        if someTr.iloc[i,22]:\n",
    "            vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,15,16,17]]\n",
    "    else:\n",
    "        vectors.iloc[i,[0,1,2,3,4,5]] =  someTr.iloc[i,[7,8,9,11,12,13]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d247fca-61a0-4b80-99cb-1510a541e508",
   "metadata": {},
   "source": [
    "Guardem aquest df `vectors` en un fitxer csv i el carreguem de nou (millor de cara a següents sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86b061d-35ac-4dda-82ec-36ef5a6cdcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.to_csv(\"vectors.csv\", sep=',', index=False)\n",
    "# vectors = pd.read_csv(r\"D:\\OneDrive\\Universitat\\5. Quint\\TFG\\RstudioPython\\vectors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631a88c6-b0a6-4ccf-850b-55ce86203341",
   "metadata": {},
   "source": [
    "A partir de `vectors` calculem la massa invariant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067ab05-8c77-4816-9525-168aa183ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_jj = pd.DataFrame(np.zeros([6_052_999,0]))\n",
    "m_jj = 1 - vectors.loc[:,\"phi1\"].apply(np.sin) * vectors.loc[:,\"phi2\"].apply(np.sin) * (vectors.loc[:,\"eta1\"] - vectors.loc[:,\"eta2\"]).apply(np.cos)\n",
    "m_jj = m_jj - vectors.loc[:,\"phi1\"].apply(np.cos) * vectors.loc[:,\"phi2\"].apply(np.cos)\n",
    "m_jj = 2*vectors.loc[:,\"p1\"] * vectors.loc[:,\"p2\"] * m_jj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df5eab1-9e3e-43c4-84ea-f306460e5f7f",
   "metadata": {},
   "source": [
    "Representem en histogrames la distribució de la massa invariant en diferents massa-signal/back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23602c6a-3344-4eb6-a142-aa8114e44abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(x=alltr.loc[:,\"pt1\"], bins='auto', color='#0504aa',\n",
    "                            alpha=0.7, rwidth=0.85)\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('Massa_jj')\n",
    "plt.ylabel('Freqüència')\n",
    "plt.title('Freqüència de la massa invariant dels dos jets no b')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
